{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from numpy.linalg import inv\n",
    "import numpy.linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "    def __init__(self,lr,n_iters,weight,x,y):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weight = weight\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def Sigmoid(self,z):\n",
    "        sign = 1 / (1+np.exp(-z))\n",
    "        return sign\n",
    "    \n",
    "    def Cost(self):\n",
    "        yhat= self.x@self.weight\n",
    "        cost = ((-self.y.T) @ np.log2(self.Sigmoid(yhat))) - ((1 - self.y).T @ np.log2(1 - self.Sigmoid(yhat)))\n",
    "        #print(yhat.shape)\n",
    "        return cost\n",
    "    \n",
    "    def Gradient(self):\n",
    "        yhat= self.x@self.weight\n",
    "        return self.x.T @ ((self.y) - self.Sigmoid(yhat))\n",
    "    \n",
    "    def fit(self):\n",
    "        loss = np.zeros((self.n_iters))\n",
    "        for i in range(self.n_iters):\n",
    "            self.weight = self.weight + (self.lr * self.Gradient())\n",
    "            \n",
    "            loss[i] = self.Cost()\n",
    "            \n",
    "        return self.weight, loss\n",
    "    \n",
    "    \n",
    "#     def pred_prob(self,z):\n",
    "    \n",
    "    \n",
    "#         return self.Sigmoid(np.dot(z,self.weight))\n",
    "        \n",
    "#     def predict(self,prediction):\n",
    "    \n",
    "#         liste = []\n",
    "\n",
    "#         for elt in prediction:\n",
    "#             if elt<0.5:\n",
    "#                 liste.append(0)\n",
    "#             else:\n",
    "#                 liste.append(1)\n",
    "#         liste = np.array(liste)\n",
    "#         liste = liste.reshape(-1,1)\n",
    "#         return liste\n",
    "    \n",
    "    def hessian(self):\n",
    "        yhat = self.x@self.weight\n",
    "        omega = self.Sigmoid(yhat) @ (1 - self.Sigmoid(yhat)).T\n",
    "        return ((-x.T) @ omega)@x -2.44641553e+05, LA.eigvals(((-x.T) @ omega)@x)\n",
    "\n",
    "    def Newton(self):\n",
    "        for i in range(self.n_iters):\n",
    "            self.weight = self.weight - inv(self.hessian()[0])@self.Gradient()\n",
    "        return self.weight\n",
    "    \n",
    "    def Good_pred(self,z):\n",
    "        \n",
    "        yhat=z@self.weight\n",
    "        \n",
    "        return np.where(self.Sigmoid(yhat)>0.5,1,0)\n",
    "    \n",
    "    \n",
    "def accuracy(prediction,y):\n",
    "    acc = y==prediction\n",
    "    return np.sum(acc)/len(y)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(x):\n",
    "    sign = 1 / (1+np.exp(-x))\n",
    "    return sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Good_pred(z, weight):\n",
    "        \n",
    "        yhat=z@weight\n",
    "        \n",
    "        return np.where(Sigmoid(yhat)>0.5,1,0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris=datasets.load_iris()   \n",
    "x=iris.data[:,:4]\n",
    "Y=(iris.target!=0)*1\n",
    "Y=Y.reshape(-1,1)\n",
    "theta = np.zeros((x.shape[1],1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in exp\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "result=LogisticRegression(0.01,10000,theta,x,Y).Newton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.71457045e+12],\n",
       "       [ 2.03883375e+12],\n",
       "       [ 1.12603750e+13],\n",
       "       [-7.58463831e+12]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log2\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in matmul\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "result=LogisticRegression(0.01,10000,theta,x,Y).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.30726813],\n",
       "       [-4.10517719],\n",
       "       [ 6.40807657],\n",
       "       [ 3.07061467]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1= Good_pred(x,result[0])\n",
    "theta = np.zeros((x.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros((x.shape[1],1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(k,data):\n",
    "    #x_train = portion[data[:20]]\n",
    "    #data = np.random.permutation(data)\n",
    "    liste = []\n",
    "    size = int(len(data) / k)\n",
    "    for i in range(k):\n",
    "      #  import pdb\n",
    "       # pdb.set_trace()\n",
    "        data_new = data[i*size:(i+1)*size,:]\n",
    "        liste.append(data_new)\n",
    "    if len(data) % k ==0:\n",
    "        return liste\n",
    "    else:\n",
    "        liste[0] = np.vstack((liste[0],data[(len(data)-1),:]))\n",
    "        return liste\n",
    "    #return liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =k_fold(5,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = np.concatenate((test[0],test[1]),axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_validation(x,y,k):\n",
    "#     x = k_fold(k,x)\n",
    "#     y = k_fold(k,y)\n",
    "#     s = 1#iteration\n",
    "#     n = 0#iteration\n",
    "#     for i in range(k):\n",
    "#         x_test = x[n:s,]\n",
    "#         x_train = np.concatenate((x[s:][0],x[:n,][0]), axis=0)\n",
    "#         n = n+1\n",
    "#         s = s+1\n",
    "#         result=LogisticRegression(0.01,100,theta,x_train,y_train).fit()\n",
    "#         #predict=LogisticRegression(0.01,100,result[0],x,y).pred_prob(x)\n",
    "#         #pred=LogisticRegression(0.01,100,result[0],x,y).predict(predict)\n",
    "#         print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_fold_cv(x,y,k):\n",
    "    \n",
    "    x=np.random.permutation(x)\n",
    "    y=np.random.permutation(y)\n",
    "    #l1=np.random.permutation(len(x))\n",
    "    #l2=np.random.permutation(len(y))\n",
    "    #x=x[l1]\n",
    "    #y=y[l2]\n",
    "    size =  int(len(x)/k)\n",
    "    i = 0\n",
    "    size1 = int (len(x)/k)\n",
    "    theta = np.zeros((x.shape[1],1))\n",
    "    acc1= []\n",
    "    for j in range(k):\n",
    "        x_test = x[i:size,]\n",
    "        x_train = np.concatenate((x[size:,],x[:i,]),axis=0)\n",
    "        y_test = y[i:size,]\n",
    "        y_train = np.concatenate((y[size:,],y[:i,]),axis=0)\n",
    "        weight = LogisticRegression(0.01,100,theta,x_train,y_train).fit()[0]\n",
    "        \n",
    "        #validation = LogisticRegression(0.01,10000,weight,x_test,y_test).Good_pred(x_test)\n",
    "        #validation= Sigmoid(x_test@weight)\n",
    "        validation = Good_pred(x_test, weight)\n",
    "        #y_pred = LogisticRegression(0.01,10000,weight,x_train,y_train).predict(validation)\n",
    "        #acc = accuracy(y_pred,y_test)\n",
    "        acc = accuracy(validation,y_test)\n",
    "        size += size\n",
    "        i = i+size1\n",
    "    \n",
    "        acc1.append(acc)\n",
    "        #print (acc)\n",
    "    return np.mean(acc1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log2\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in matmul\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6353083853083853"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_fold_cv(x,Y,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_elimination(data, target, significance_level):\n",
    "    feature=data.columns.tolist()\n",
    "    while(len(feature)>0):\n",
    "        feature_with_constant=sm.add(data[feature])\n",
    "        p_value=sm.OLS(target,feature_with_constant).fit().pvalue[1:]\n",
    "        max_p_value=p_value.max()\n",
    "        if max_p_value>=significance_level:\n",
    "            removed_feature=p_value.idxmax()\n",
    "            feature.remove(removed_feature)\n",
    "        else:\n",
    "            break\n",
    "            return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris=datasets.load_iris()   \n",
    "x=iris.data[:,:4]\n",
    "Y=(iris.target!=0)*1\n",
    "Y=Y.reshape(-1,1)\n",
    "theta = np.zeros((x.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(X,y,k):\n",
    "    cmpt=0\n",
    "    f=1\n",
    "    for j in range(X.shape[1]):\n",
    "        X_non_used=X[:,cmpt:f]\n",
    "        X_used=np.concatenate((X[:,f:],X[:,:cmpt]),axis=1)\n",
    "        #import pdb\n",
    "        #pdb=pdb.set_trace()\n",
    "        cmpt+=1\n",
    "        f+=1\n",
    "        #K_fold_cv(X_used,y,k)\n",
    "        print( K_fold_cv(X_used,y,k))\n",
    "        #print(X_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5837020727681257\n",
      "0.6166908965441676\n",
      "0.6223330597769197\n",
      "0.6050397409217174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log2\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in matmul\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "feature_selection(x,Y,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x.iloc[:,0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_fold_cv_data(x,y,k):\n",
    "    \n",
    "    x=np.random.permutation(x)\n",
    "    y=np.random.permutation(y)\n",
    "    #l1=np.random.permutation(len(x))\n",
    "    #l2=np.random.permutation(len(y))\n",
    "    #x=x[l1]\n",
    "    #y=y[l2]\n",
    "    size =  int(len(x)/k)\n",
    "    i = 0\n",
    "    size1 = int (len(x)/k)\n",
    "    theta = np.zeros((x.shape[1],1))\n",
    "    acc1= []\n",
    "    for j in range(k):\n",
    "        x_test = x[i:size,]\n",
    "        x_train = np.concatenate((x[size:,],x[:i,]),axis=0)\n",
    "        y_test = y[i:size,]\n",
    "        y_train = np.concatenate((y[size:,],y[:i,]),axis=0)\n",
    "        weight = LogisticRegression(0.01,100,theta,x_train,y_train).fit()[0]\n",
    "        \n",
    "        #validation = LogisticRegression(0.01,10000,weight,x_test,y_test).Good_pred(x_test)\n",
    "        #validation= Sigmoid(x_test@weight)\n",
    "        validation = Good_pred(x_test, weight)\n",
    "        #y_pred = LogisticRegression(0.01,10000,weight,x_train,y_train).predict(validation)\n",
    "        #acc = accuracy(y_pred,y_test)\n",
    "        acc = accuracy(validation,y_test)\n",
    "        size += size\n",
    "        i = i+size1\n",
    "    \n",
    "        acc1.append(acc)\n",
    "        #print (acc)\n",
    "    return np.mean(acc1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_elimination(data, target, significence_level=0.05):\n",
    "    feature=data.columns.tolist()\n",
    "    while(len(feature)>0):\n",
    "        feature_with_constant=sm.add(data[feature])\n",
    "        p_value=sm.OLS(target, feature_with_constant).fit().pvalue[1:]\n",
    "        max_p_value=p_value.max()\n",
    "        if max_p_value>significence_level:\n",
    "            retracted_feature=p_value.idxmax()\n",
    "            feature.remove(retracted_feature)\n",
    "        else:\n",
    "            break\n",
    "            return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv(k,x):\n",
    "    split=[]\n",
    "    m=len(x)\n",
    "    size=int(m/k)\n",
    "    for i in range(d):\n",
    "        x_new=x[i*size:(i+1)*size,:]\n",
    "        split.append(x_new)\n",
    "        x_new=0\n",
    "    if m%k==0:\n",
    "        return split\n",
    "    else:\n",
    "        split[0]=np.vstack((split[0],x[m-1,]))\n",
    "        return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_fold_cv(k,x,y):\n",
    "    m=len(x)\n",
    "    size0=int(m/k)\n",
    "    size1=int(m/k)\n",
    "    i=0\n",
    "    for j in range(k):\n",
    "        x_test=x[i:size,]\n",
    "        x_train=np.concatenate((x[size:,],x[:i,]), axis=0)\n",
    "        y_test=y[i:size,]\n",
    "        y_train=np.concatenate((y[size:,],y[:i,]),axis=0)\n",
    "        validation="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
