{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Gaussian discriminant analysis, Naive bayes and Logistic regression implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as m\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_table('drugLibTest_raw.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>urlDrugName</th>\n",
       "      <th>rating</th>\n",
       "      <th>effectiveness</th>\n",
       "      <th>sideEffects</th>\n",
       "      <th>condition</th>\n",
       "      <th>benefitsReview</th>\n",
       "      <th>sideEffectsReview</th>\n",
       "      <th>commentsReview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1366</td>\n",
       "      <td>biaxin</td>\n",
       "      <td>9</td>\n",
       "      <td>Considerably Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>sinus infection</td>\n",
       "      <td>The antibiotic may have destroyed bacteria cau...</td>\n",
       "      <td>Some back pain, some nauseau.</td>\n",
       "      <td>Took the antibiotics for 14 days. Sinus infect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3724</td>\n",
       "      <td>lamictal</td>\n",
       "      <td>9</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>bipolar disorder</td>\n",
       "      <td>Lamictal stabilized my serious mood swings. On...</td>\n",
       "      <td>Drowsiness, a bit of mental numbness. If you t...</td>\n",
       "      <td>Severe mood swings between hypomania and depre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3824</td>\n",
       "      <td>depakene</td>\n",
       "      <td>4</td>\n",
       "      <td>Moderately Effective</td>\n",
       "      <td>Severe Side Effects</td>\n",
       "      <td>bipolar disorder</td>\n",
       "      <td>Initial benefits were comparable to the brand ...</td>\n",
       "      <td>Depakene has a very thin coating, which caused...</td>\n",
       "      <td>Depakote was prescribed to me by a Kaiser psyc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>969</td>\n",
       "      <td>sarafem</td>\n",
       "      <td>10</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>No Side Effects</td>\n",
       "      <td>bi-polar / anxiety</td>\n",
       "      <td>It controlls my mood swings. It helps me think...</td>\n",
       "      <td>I didnt really notice any side effects.</td>\n",
       "      <td>This drug may not be for everyone but its wond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>696</td>\n",
       "      <td>accutane</td>\n",
       "      <td>10</td>\n",
       "      <td>Highly Effective</td>\n",
       "      <td>Mild Side Effects</td>\n",
       "      <td>nodular acne</td>\n",
       "      <td>Within one week of treatment superficial acne ...</td>\n",
       "      <td>Side effects included moderate to severe dry s...</td>\n",
       "      <td>Drug was taken in gelatin tablet at 0.5 mg per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 urlDrugName  rating           effectiveness  \\\n",
       "0        1366      biaxin       9  Considerably Effective   \n",
       "1        3724    lamictal       9        Highly Effective   \n",
       "2        3824    depakene       4    Moderately Effective   \n",
       "3         969     sarafem      10        Highly Effective   \n",
       "4         696    accutane      10        Highly Effective   \n",
       "\n",
       "           sideEffects           condition  \\\n",
       "0    Mild Side Effects     sinus infection   \n",
       "1    Mild Side Effects    bipolar disorder   \n",
       "2  Severe Side Effects    bipolar disorder   \n",
       "3      No Side Effects  bi-polar / anxiety   \n",
       "4    Mild Side Effects        nodular acne   \n",
       "\n",
       "                                      benefitsReview  \\\n",
       "0  The antibiotic may have destroyed bacteria cau...   \n",
       "1  Lamictal stabilized my serious mood swings. On...   \n",
       "2  Initial benefits were comparable to the brand ...   \n",
       "3  It controlls my mood swings. It helps me think...   \n",
       "4  Within one week of treatment superficial acne ...   \n",
       "\n",
       "                                   sideEffectsReview  \\\n",
       "0                      Some back pain, some nauseau.   \n",
       "1  Drowsiness, a bit of mental numbness. If you t...   \n",
       "2  Depakene has a very thin coating, which caused...   \n",
       "3            I didnt really notice any side effects.   \n",
       "4  Side effects included moderate to severe dry s...   \n",
       "\n",
       "                                      commentsReview  \n",
       "0  Took the antibiotics for 14 days. Sinus infect...  \n",
       "1  Severe mood swings between hypomania and depre...  \n",
       "2  Depakote was prescribed to me by a Kaiser psyc...  \n",
       "3  This drug may not be for everyone but its wond...  \n",
       "4  Drug was taken in gelatin tablet at 0.5 mg per...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1036 entries, 0 to 1035\n",
      "Data columns (total 9 columns):\n",
      "Unnamed: 0           1036 non-null int64\n",
      "urlDrugName          1036 non-null object\n",
      "rating               1036 non-null int64\n",
      "effectiveness        1036 non-null object\n",
      "sideEffects          1036 non-null object\n",
      "condition            1036 non-null object\n",
      "benefitsReview       1036 non-null object\n",
      "sideEffectsReview    1036 non-null object\n",
      "commentsReview       1036 non-null object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 72.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of features to binary numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 1*(data['rating']>5)\n",
    "df = data.drop(['Unnamed: 0','rating'],axis=1)\n",
    "\n",
    "def tovec(text):\n",
    "    # create the transform\n",
    "    vectorizer = CountVectorizer(binary=True,stop_words='english',max_features=90)\n",
    "    # tokenize and build vocab\n",
    "    vectorizer.fit(text)\n",
    "    # summarize\n",
    "    k = vectorizer.vocabulary_\n",
    "    # encode document\n",
    "    vector = vectorizer.transform(text)\n",
    "    # summarize encoded vector\n",
    "    return vector.toarray()\n",
    "data_new=df['urlDrugName']+' '+df['effectiveness']+' '+df['sideEffects']+' '+df['condition']+' '+df['benefitsReview']+' '+df['sideEffectsReview']+' '+df['commentsReview']\n",
    "X = tovec(data_new)\n",
    "df_features = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9  ...  80  81  82  83  84  85  86  87  \\\n",
       "0   0   0   0   0   0   0   0   0   0   1 ...   0   0   0   0   0   0   0   0   \n",
       "1   0   1   0   0   0   0   0   0   0   0 ...   1   0   0   0   0   0   1   0   \n",
       "2   0   0   0   1   0   0   1   0   0   0 ...   0   0   0   1   0   1   0   0   \n",
       "3   0   0   0   1   0   0   0   1   0   0 ...   0   0   0   0   0   0   0   0   \n",
       "4   0   0   1   0   0   0   0   0   0   0 ...   0   0   1   1   0   0   0   0   \n",
       "\n",
       "   88  89  \n",
       "0   0   0  \n",
       "1   0   0  \n",
       "2   0   1  \n",
       "3   0   0  \n",
       "4   0   0  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculus of Gaussian discriminant analysis parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_phi(Y):\n",
    "    m = length(Y)\n",
    "    return sum(x(x==1), Y)/m\n",
    "\n",
    "def calculate_sigma(X, Y, mu0, mu1):\n",
    "    m = length(Y)\n",
    "    sqr_sum = zeros(size(X)[2], size(X)[2])\n",
    "    for i in range(m):\n",
    "        xi = X[i,:]\n",
    "        yi = Y[i]\n",
    "        sqr = sum((xi-mu1)*(xi-mu1).T(yi == 1)) \n",
    "        sqr_sum = sqr_sum + sqr\n",
    " \n",
    "    return sqr_sum/m\n",
    "\n",
    "\n",
    "def calculate_mu1(X, Y):\n",
    "    m = length(Y)\n",
    "    y_pos = count(x(x==1), Y)\n",
    "    conditional_sum_x = zeros(X[1,:])\n",
    "    for i in range(m):\n",
    "        xi = X[i,:]\n",
    "        yi = Y[i]\n",
    "        conditional_sum_x = conditional_sum_x + sum(xi(yi == 1), zeros(xi))\n",
    "    return (1/m)*conditional_sum_x/y_pos\n",
    "\n",
    "\n",
    "def calculate_mu0(X, Y):\n",
    "    m = length(Y)\n",
    "    y_neg = count(x(x==0), Y)\n",
    "    conditional_sum_x = zeros(X[1,:])\n",
    "    for i in range(m):\n",
    "        xi = X[i,:]\n",
    "        yi = Y[i]\n",
    "        conditional_sum_x = conditional_sum_x + sum(xi(yi == 0), zeros(xi))\n",
    "    return (1/m)*conditional_sum_x/y_neg\n",
    "\n",
    "def calculate_px_py(x, mu, sigma):\n",
    "    n = 1\n",
    "    pi = 3.14\n",
    "    dim = len(mu)\n",
    "    return ((1/(2*np.pi)^(dim/2)*np.sqrt(m.det(sigma)))*np.exp(-0.5*np.transpose(x-mu)*np.linalg.inv(sigma)*(x-mu)))\n",
    "\n",
    "                                                  \n",
    "def calculate_py(y, phi):\n",
    "    return sum(phi(y==1), (1-phi))\n",
    "\n",
    "def predict(self, X):\n",
    "        y_pred = []\n",
    "        for sample in X:\n",
    "            h = sample.dot(self.w)\n",
    "            y = 1 * (h < 0)\n",
    "            y_pred.append(y)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov(x, y):\n",
    "    xbar, ybar = x.mean(), y.mean()\n",
    "    return np.sum((x - xbar)*(y - ybar))/(len(x) - 1)\n",
    "\n",
    "def calculate_covariance_matrix(X):\n",
    "    return np.array([[cov(X[0], X[0]), cov(X[0], X[1])], \\\n",
    "                     [cov(X[1], X[0]), cov(X[1], X[1])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian discriminant analysis class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gaussian_Discriminant_Analysis():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "\n",
    "    def transform(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        # Project data onto vector\n",
    "        X_transform = X.dot(self.w)\n",
    "        return X_transform\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Separate data by class\n",
    "        X1 = X[y == 0]\n",
    "        X2 = X[y == 1]\n",
    "\n",
    "        # Calculate the covariance matrices of the two datasets\n",
    "        cov1 = calculate_covariance_matrix(X1)\n",
    "        cov2 = calculate_covariance_matrix(X2)\n",
    "        cov_tot = cov1 + cov2\n",
    "\n",
    "        # Calculate the mean of the two datasets\n",
    "        mean1 = X1.mean(0)\n",
    "        mean2 = X2.mean(0)\n",
    "        mean_diff = np.atleast_1d(mean1 - mean2) #convert to an array to 1D at least\n",
    "\n",
    "        # Determine the vector which when X is projected onto it best separates the\n",
    "        # data by class. w = (mean1 - mean2) / (cov1 + cov2)\n",
    "        self.w = np.linalg.pinv(cov_tot).dot(mean_diff)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "        for sample in X:\n",
    "            h = sample.dot(self.w)\n",
    "            y = 1 * (h < 0)\n",
    "            y_pred.append(y)\n",
    "        return y_pred\n",
    "    \n",
    "    def accuracy(self,X,y):\n",
    "        y_pred = self.predict(X)\n",
    "        accu=np.sum(y_pred == y)/len(y)\n",
    "        return accu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of Gaussian discriminant analysis on iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=datasets.load_iris()\n",
    "x1=data.data[:,:2]\n",
    "y1=(data.target!=0)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Gaussian_Discriminant_Analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.accuracy(x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of Gaussian discriminant analysis on our initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=Gaussian_Discriminant_Analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive bayes implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Naive_bayes:\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def fit(self):\n",
    "        data = self.X\n",
    "        target = self.y\n",
    "        x_1y_0=[]\n",
    "        x_1y_1=[]\n",
    "        y_new=[]\n",
    "        count_3=0\n",
    "        count_4=0\n",
    "        for j in range(data.shape[1]):\n",
    "            count=0\n",
    "            count_2=0\n",
    "            for i in range(data.shape[0]):\n",
    "#                 print(data,target,i,j)\n",
    "                if y[i]==0 and data[i][j]==1:\n",
    "                    count +=1\n",
    "                if y[i]==1 and data[i][j]==1:\n",
    "                    count_2 +=1\n",
    "                if j==0 and y[i]==1:\n",
    "                    count_3+=1\n",
    "                if j==0 and y[i]==0:\n",
    "                    count_4+=1\n",
    "            length_1=count_3\n",
    "            length_0=count_4\n",
    "            x_1y_0.append(count/length_0)\n",
    "            x_1y_1.append(count_2/length_1)\n",
    "        y_new.append(count_3/(length_0+length_1))\n",
    "        return x_1y_0,x_1y_1,y_new\n",
    "\n",
    "    def Bernouilli(self,x,phi):\n",
    "        return (phi**x)*(1-phi)**(1-x)\n",
    "\n",
    "    def predict(self,x):\n",
    "        phi_x1_y0,phi_x1_y1,p = self.fit()\n",
    "        pred = np.zeros(x.shape[0])\n",
    "        for i in range(len(x)):\n",
    "            prb1 = 1\n",
    "            prb2 = 1\n",
    "            for j in range(x.shape[1]):\n",
    "                prb1*= self.Bernouilli(x[i,j],phi_x1_y0[j])\n",
    "                prb2*= self.Bernouilli(x[i,j],phi_x1_y1[j])\n",
    "            prb1 = prb1*(1-p[0])\n",
    "            prb2 = prb2*(p[0])\n",
    "            pred[i] = np.argmax([prb1,prb2])\n",
    "        return pred\n",
    "\n",
    "    def accuracy(self,test,pred):\n",
    "        c=0\n",
    "        for i in range(len(pred)):\n",
    "            if(test.iloc[i]==pred[i]):\n",
    "                c+=1\n",
    "        c=c/len(pred)\n",
    "        return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Naive_bayes(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.08928571428571429,\n",
       "  0.16666666666666666,\n",
       "  0.10714285714285714,\n",
       "  0.1488095238095238,\n",
       "  0.125,\n",
       "  0.05952380952380952,\n",
       "  0.11904761904761904,\n",
       "  0.15476190476190477,\n",
       "  0.07142857142857142,\n",
       "  0.32142857142857145,\n",
       "  0.08928571428571429,\n",
       "  0.16666666666666666,\n",
       "  0.43452380952380953,\n",
       "  0.23214285714285715,\n",
       "  0.2619047619047619,\n",
       "  0.27976190476190477,\n",
       "  0.08928571428571429,\n",
       "  0.16666666666666666,\n",
       "  0.1130952380952381,\n",
       "  0.20238095238095238,\n",
       "  0.25,\n",
       "  0.125,\n",
       "  0.1130952380952381,\n",
       "  0.9226190476190477,\n",
       "  1.0,\n",
       "  0.05952380952380952,\n",
       "  0.05357142857142857,\n",
       "  0.15476190476190477,\n",
       "  0.23809523809523808,\n",
       "  0.14285714285714285,\n",
       "  0.16071428571428573,\n",
       "  0.06547619047619048,\n",
       "  0.08928571428571429,\n",
       "  0.07738095238095238,\n",
       "  0.1130952380952381,\n",
       "  0.1130952380952381,\n",
       "  0.05952380952380952,\n",
       "  0.35714285714285715,\n",
       "  0.08928571428571429,\n",
       "  0.1130952380952381,\n",
       "  0.09523809523809523,\n",
       "  0.16071428571428573,\n",
       "  0.10119047619047619,\n",
       "  0.21428571428571427,\n",
       "  0.10714285714285714,\n",
       "  0.13690476190476192,\n",
       "  0.2261904761904762,\n",
       "  0.08333333333333333,\n",
       "  0.18452380952380953,\n",
       "  0.39880952380952384,\n",
       "  0.2857142857142857,\n",
       "  0.17261904761904762,\n",
       "  0.10119047619047619,\n",
       "  0.20833333333333334,\n",
       "  0.125,\n",
       "  0.08928571428571429,\n",
       "  0.1130952380952381,\n",
       "  0.11904761904761904,\n",
       "  0.11904761904761904,\n",
       "  0.08928571428571429,\n",
       "  0.19047619047619047,\n",
       "  0.10119047619047619,\n",
       "  0.17261904761904762,\n",
       "  0.10714285714285714,\n",
       "  0.08333333333333333,\n",
       "  0.2976190476190476,\n",
       "  0.1488095238095238,\n",
       "  0.17857142857142858,\n",
       "  0.19047619047619047,\n",
       "  0.08333333333333333,\n",
       "  0.07142857142857142,\n",
       "  0.13095238095238096,\n",
       "  0.10119047619047619,\n",
       "  0.08928571428571429,\n",
       "  0.3630952380952381,\n",
       "  0.24404761904761904,\n",
       "  0.1130952380952381,\n",
       "  0.27380952380952384,\n",
       "  0.17857142857142858,\n",
       "  0.125,\n",
       "  0.125,\n",
       "  0.05357142857142857,\n",
       "  0.17261904761904762,\n",
       "  0.19642857142857142,\n",
       "  0.10714285714285714,\n",
       "  0.15476190476190477,\n",
       "  0.13095238095238096,\n",
       "  0.1130952380952381,\n",
       "  0.13095238095238096,\n",
       "  0.22023809523809523],\n",
       " [0.1,\n",
       "  0.12,\n",
       "  0.08,\n",
       "  0.11714285714285715,\n",
       "  0.09428571428571429,\n",
       "  0.06285714285714286,\n",
       "  0.09142857142857143,\n",
       "  0.16285714285714287,\n",
       "  0.13428571428571429,\n",
       "  0.2857142857142857,\n",
       "  0.11142857142857143,\n",
       "  0.16857142857142857,\n",
       "  0.43142857142857144,\n",
       "  0.22285714285714286,\n",
       "  0.14,\n",
       "  0.26,\n",
       "  0.09428571428571429,\n",
       "  0.22857142857142856,\n",
       "  0.11428571428571428,\n",
       "  0.17142857142857143,\n",
       "  0.2542857142857143,\n",
       "  0.1457142857142857,\n",
       "  0.14,\n",
       "  0.9371428571428572,\n",
       "  1.0,\n",
       "  0.07714285714285714,\n",
       "  0.07714285714285714,\n",
       "  0.11428571428571428,\n",
       "  0.16857142857142857,\n",
       "  0.08857142857142856,\n",
       "  0.13714285714285715,\n",
       "  0.07714285714285714,\n",
       "  0.09714285714285714,\n",
       "  0.13428571428571429,\n",
       "  0.08571428571428572,\n",
       "  0.09714285714285714,\n",
       "  0.11714285714285715,\n",
       "  0.45714285714285713,\n",
       "  0.13142857142857142,\n",
       "  0.12,\n",
       "  0.07714285714285714,\n",
       "  0.11428571428571428,\n",
       "  0.12,\n",
       "  0.19142857142857142,\n",
       "  0.07428571428571429,\n",
       "  0.11142857142857143,\n",
       "  0.24,\n",
       "  0.10571428571428572,\n",
       "  0.18857142857142858,\n",
       "  0.37714285714285717,\n",
       "  0.24,\n",
       "  0.13428571428571429,\n",
       "  0.11428571428571428,\n",
       "  0.2,\n",
       "  0.18,\n",
       "  0.08571428571428572,\n",
       "  0.08,\n",
       "  0.22285714285714286,\n",
       "  0.06857142857142857,\n",
       "  0.09428571428571429,\n",
       "  0.16857142857142857,\n",
       "  0.1457142857142857,\n",
       "  0.13142857142857142,\n",
       "  0.08285714285714285,\n",
       "  0.12,\n",
       "  0.2542857142857143,\n",
       "  0.16857142857142857,\n",
       "  0.15142857142857144,\n",
       "  0.2,\n",
       "  0.09142857142857143,\n",
       "  0.07714285714285714,\n",
       "  0.13428571428571429,\n",
       "  0.16285714285714287,\n",
       "  0.15428571428571428,\n",
       "  0.3914285714285714,\n",
       "  0.2257142857142857,\n",
       "  0.14,\n",
       "  0.21714285714285714,\n",
       "  0.2342857142857143,\n",
       "  0.12857142857142856,\n",
       "  0.12857142857142856,\n",
       "  0.12285714285714286,\n",
       "  0.1657142857142857,\n",
       "  0.14,\n",
       "  0.12,\n",
       "  0.11428571428571428,\n",
       "  0.14,\n",
       "  0.09714285714285714,\n",
       "  0.08,\n",
       "  0.17714285714285713],\n",
       " [0.6756756756756757])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.accuracy(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:  0.693050193050193\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy is: ',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and test on 60% 40% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = np.random.permutation(len(X))\n",
    "portion = 40\n",
    "\n",
    "\"\"\"\n",
    "    Split your data into train and test using the order and permutation variable\n",
    "\"\"\"\n",
    "train_x = X[order[portion:]]\n",
    "train_y = y[order[portion:]]\n",
    "\n",
    "test_x= X[order[:portion]]\n",
    "test_y= y[order[:portion]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Naive_bayes(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.09764309764309764,\n",
       "  0.13468013468013468,\n",
       "  0.0707070707070707,\n",
       "  0.13468013468013468,\n",
       "  0.11784511784511785,\n",
       "  0.07744107744107744,\n",
       "  0.11447811447811448,\n",
       "  0.16161616161616163,\n",
       "  0.11447811447811448,\n",
       "  0.3265993265993266,\n",
       "  0.1111111111111111,\n",
       "  0.16161616161616163,\n",
       "  0.45791245791245794,\n",
       "  0.22895622895622897,\n",
       "  0.2053872053872054,\n",
       "  0.31986531986531985,\n",
       "  0.13804713804713806,\n",
       "  0.21548821548821548,\n",
       "  0.13468013468013468,\n",
       "  0.18855218855218855,\n",
       "  0.26936026936026936,\n",
       "  0.09090909090909091,\n",
       "  0.1919191919191919,\n",
       "  0.936026936026936,\n",
       "  1.0,\n",
       "  0.06397306397306397,\n",
       "  0.09764309764309764,\n",
       "  0.12121212121212122,\n",
       "  0.20202020202020202,\n",
       "  0.13804713804713806,\n",
       "  0.16498316498316498,\n",
       "  0.10101010101010101,\n",
       "  0.09090909090909091,\n",
       "  0.12794612794612795,\n",
       "  0.08754208754208755,\n",
       "  0.10101010101010101,\n",
       "  0.10774410774410774,\n",
       "  0.3939393939393939,\n",
       "  0.09427609427609428,\n",
       "  0.12794612794612795,\n",
       "  0.08080808080808081,\n",
       "  0.15488215488215487,\n",
       "  0.09427609427609428,\n",
       "  0.20202020202020202,\n",
       "  0.08080808080808081,\n",
       "  0.1111111111111111,\n",
       "  0.23905723905723905,\n",
       "  0.08080808080808081,\n",
       "  0.2053872053872054,\n",
       "  0.3367003367003367,\n",
       "  0.265993265993266,\n",
       "  0.15151515151515152,\n",
       "  0.10101010101010101,\n",
       "  0.2255892255892256,\n",
       "  0.15824915824915825,\n",
       "  0.08080808080808081,\n",
       "  0.08080808080808081,\n",
       "  0.18518518518518517,\n",
       "  0.05723905723905724,\n",
       "  0.11447811447811448,\n",
       "  0.16498316498316498,\n",
       "  0.16498316498316498,\n",
       "  0.13804713804713806,\n",
       "  0.11447811447811448,\n",
       "  0.12121212121212122,\n",
       "  0.26262626262626265,\n",
       "  0.1414141414141414,\n",
       "  0.18855218855218855,\n",
       "  0.18181818181818182,\n",
       "  0.10101010101010101,\n",
       "  0.08080808080808081,\n",
       "  0.12794612794612795,\n",
       "  0.1447811447811448,\n",
       "  0.1414141414141414,\n",
       "  0.3569023569023569,\n",
       "  0.2828282828282828,\n",
       "  0.14814814814814814,\n",
       "  0.265993265993266,\n",
       "  0.18181818181818182,\n",
       "  0.13468013468013468,\n",
       "  0.12121212121212122,\n",
       "  0.09764309764309764,\n",
       "  0.1111111111111111,\n",
       "  0.16498316498316498,\n",
       "  0.13131313131313133,\n",
       "  0.13468013468013468,\n",
       "  0.1414141414141414,\n",
       "  0.09427609427609428,\n",
       "  0.09427609427609428,\n",
       "  0.22895622895622897],\n",
       " [0.08869814020028613,\n",
       "  0.12875536480686695,\n",
       "  0.10157367668097282,\n",
       "  0.12017167381974249,\n",
       "  0.09012875536480687,\n",
       "  0.07868383404864092,\n",
       "  0.10872675250357654,\n",
       "  0.16738197424892703,\n",
       "  0.09871244635193133,\n",
       "  0.30042918454935624,\n",
       "  0.09155937052932761,\n",
       "  0.17024320457796852,\n",
       "  0.402002861230329,\n",
       "  0.23032904148783978,\n",
       "  0.1759656652360515,\n",
       "  0.24892703862660945,\n",
       "  0.08869814020028613,\n",
       "  0.19027181688125894,\n",
       "  0.10872675250357654,\n",
       "  0.15879828326180256,\n",
       "  0.27896995708154504,\n",
       "  0.13447782546494993,\n",
       "  0.11731044349070101,\n",
       "  0.9241773962804005,\n",
       "  1.0,\n",
       "  0.09155937052932761,\n",
       "  0.09155937052932761,\n",
       "  0.12303290414878398,\n",
       "  0.17167381974248927,\n",
       "  0.1072961373390558,\n",
       "  0.16452074391988555,\n",
       "  0.0944206008583691,\n",
       "  0.0815450643776824,\n",
       "  0.1072961373390558,\n",
       "  0.09728183118741059,\n",
       "  0.10872675250357654,\n",
       "  0.0944206008583691,\n",
       "  0.40486409155937053,\n",
       "  0.1072961373390558,\n",
       "  0.10586552217453506,\n",
       "  0.09298998569384835,\n",
       "  0.13733905579399142,\n",
       "  0.12446351931330472,\n",
       "  0.2017167381974249,\n",
       "  0.0944206008583691,\n",
       "  0.11158798283261803,\n",
       "  0.21602288984263232,\n",
       "  0.08011444921316166,\n",
       "  0.16165951359084407,\n",
       "  0.3791130185979971,\n",
       "  0.24034334763948498,\n",
       "  0.16022889842632332,\n",
       "  0.1072961373390558,\n",
       "  0.1988555078683834,\n",
       "  0.1459227467811159,\n",
       "  0.09298998569384835,\n",
       "  0.09012875536480687,\n",
       "  0.18454935622317598,\n",
       "  0.09585121602288985,\n",
       "  0.08011444921316166,\n",
       "  0.17882689556509299,\n",
       "  0.13304721030042918,\n",
       "  0.15593705293276108,\n",
       "  0.10586552217453506,\n",
       "  0.10300429184549356,\n",
       "  0.2947067238912732,\n",
       "  0.1473533619456366,\n",
       "  0.1459227467811159,\n",
       "  0.18741058655221746,\n",
       "  0.07296137339055794,\n",
       "  0.09298998569384835,\n",
       "  0.12732474964234622,\n",
       "  0.15879828326180256,\n",
       "  0.13733905579399142,\n",
       "  0.36337625178826893,\n",
       "  0.23605150214592274,\n",
       "  0.12017167381974249,\n",
       "  0.24034334763948498,\n",
       "  0.20457796852646637,\n",
       "  0.12160228898426323,\n",
       "  0.11301859799713877,\n",
       "  0.09012875536480687,\n",
       "  0.16165951359084407,\n",
       "  0.17882689556509299,\n",
       "  0.12017167381974249,\n",
       "  0.11731044349070101,\n",
       "  0.13590844062947066,\n",
       "  0.0844062947067239,\n",
       "  0.10300429184549356,\n",
       "  0.1659513590844063],\n",
       " [0.7018072289156626])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.accuracy(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:  0.637065637065637\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy is: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self,lr,n_iters,weight,x,y):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weight = weight\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def Sigmoid(self,z):\n",
    "        sign = 1 / (1+np.exp(-z))\n",
    "        return sign\n",
    "    \n",
    "    def Cost(self):\n",
    "        yhat= self.x@self.weight\n",
    "        cost = ((-self.y.T) @ np.log2(self.Sigmoid(yhat))) - ((1 - self.y).T @ np.log2(1 - self.Sigmoid(yhat)))\n",
    "        #print(yhat.shape)\n",
    "        return cost\n",
    "    \n",
    "    def Gradient(self):\n",
    "        yhat= self.x@self.weight\n",
    "        return self.x.T @ ((self.y) - self.Sigmoid(yhat))\n",
    "    \n",
    "    def fit(self):\n",
    "        loss = np.zeros((self.n_iters))\n",
    "        for i in range(self.n_iters):\n",
    "            self.weight = self.weight + (self.lr * self.Gradient())\n",
    "            \n",
    "            loss[i] = self.Cost()\n",
    "            \n",
    "        return self.weight, loss\n",
    "    \n",
    "    \n",
    "    def pred_prob(self,z):\n",
    "            return self.Sigmoid(np.dot(z,self.weight))\n",
    "    \n",
    "    def predict(self,prediction):\n",
    "    \n",
    "         liste = []\n",
    "\n",
    "         for elt in prediction:\n",
    "                if elt<0.5:\n",
    "                    liste.append(0)\n",
    "                else:\n",
    "                    liste.append(1)\n",
    "                liste = np.array(liste)\n",
    "                liste = liste.reshape(-1,1)\n",
    "                return liste\n",
    "    \n",
    "    def hessian(self):\n",
    "        yhat = self.x@self.weight\n",
    "        omega = self.Sigmoid(yhat) @ (1 - self.Sigmoid(yhat)).T\n",
    "        return ((-x.T) @ omega)@x -2.44641553e+05, LA.eigvals(((-x.T) @ omega)@x)\n",
    "\n",
    "    def Newton(self):\n",
    "        for i in range(self.n_iters):\n",
    "            self.weight = self.weight - inv(self.hessian()[0])@self.Gradient()\n",
    "        return self.weight\n",
    "    \n",
    "    def Good_pred(self,z):\n",
    "        \n",
    "        yhat=z@self.weight\n",
    "        \n",
    "        return np.where(self.Sigmoid(yhat)>0.5,1,0)\n",
    "    \n",
    "    \n",
    "def accuracy(prediction,y):\n",
    "    acc = y==prediction\n",
    "    return np.sum(acc)/len(y)\n",
    "        \n",
    "def Sigmoid(x):\n",
    "    sign = 1 / (1+np.exp(-x))\n",
    "    return sign\n",
    "\n",
    "def Good_pred(z, weight):\n",
    "        \n",
    "        yhat=z@weight\n",
    "        \n",
    "        return np.where(Sigmoid(yhat)>0.5,1,0)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=datasets.load_iris()\n",
    "x1=data1.data[:,:2]\n",
    "y1=(data1.target!=0)*1\n",
    "y1=y1.reshape(-1,1)\n",
    "theta = np.zeros((x1.shape[1],1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression(0.01,10000,theta,x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log2\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in matmul\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "result=model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1= Good_pred(x1,result[0])\n",
    "theta = np.zeros((x1.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9933333333333333"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(pred1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test logistic regression on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1 = np.zeros((X_train.shape[1],1))\n",
    "model2=LogisticRegression(0.01,10000,theta1,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_feature_selection(X, y, n_features=2):\n",
    "    results = {'best':[]}\n",
    "    count = 0\n",
    "    feature_list = []\n",
    "    while len(feature_list) < n_features:\n",
    "        results[count] = []\n",
    "        for i in range(len(X[0])):\n",
    "            if i not in feature_list: \n",
    "                train_model_save_result(X, y, results[count])\n",
    "        best_result = get_best_result(results[count])\n",
    "        feature_list = best_result['features']\n",
    "        results['best'].append(best_result)\n",
    "        count+= 1\n",
    "    compute_best_features(results, n_features)\n",
    "    return results\n",
    "\n",
    "def backward_feature_selection(X, y, n_features=2):\n",
    "    results = {'best':[]}\n",
    "    count = 0\n",
    "    feature_list = range(len(X[0]))\n",
    "    while len(feature_list) > 1:\n",
    "        results[count] = []\n",
    "        for i in range(len(feature_list)):\n",
    "            idx = feature_list[0:i] + feature_list[i+1:]\n",
    "            train_model_save_result(X, y, idx, results[count])\n",
    "        best_result = get_best_result(results[count])\n",
    "        feature_list = best_result['features']\n",
    "        results['best'].append(best_result)\n",
    "        count+= 1\n",
    "    compute_best_features(results, n_features)\n",
    "    return results\n",
    "\n",
    "def compute_best_features(results, n_features):\n",
    "    best_result = None\n",
    "    for result in results['best']:\n",
    "        if len(result['features']) <= n_features:\n",
    "            if not best_result: \n",
    "                best_result = result\n",
    "            elif best_result['score'] < result['score']: \n",
    "                best_result = result\n",
    "    results['best_features'] = best_result['features']\n",
    "    \n",
    "def train_model_save_result(X, y, result_storage):\n",
    "    #X_ = X[:, idx]\n",
    "    result = 0\n",
    "    model = Naive_bayes(X,y)\n",
    "    model.fit()\n",
    "    acc = accuracy(y, model.predict(X))\n",
    "    result += acc\n",
    "    print({'accuracy ' :acc})\n",
    "    result_storage.append({'score': result})\n",
    "    \n",
    "def get_best_result(result_storage):\n",
    "    best = None\n",
    "    for model in result_storage:\n",
    "        if not best: best = model\n",
    "        elif model['score'] > best['score']:best = model\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By observing the different accuracy of Gaussian discriminant analysis, Naive bayes and Logistic regression we can say that the Logistic regression model is better to use on this data than the Gaussian discriminant analysis and Naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
