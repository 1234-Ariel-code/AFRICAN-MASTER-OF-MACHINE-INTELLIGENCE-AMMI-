{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]\n",
    "y = (iris.target != 0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, lr=0.01, num_iter=100000, fit_intercept=True, verbose=False):\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def __add_intercept(self, X):\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "    def __sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    \n",
    "    def __loss(self, h, y):\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "        \n",
    "        # weights initialization\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "        \n",
    "        for i in range(self.num_iter):\n",
    "            z = np.dot(X, self.theta)\n",
    "            h = self.__sigmoid(z)\n",
    "            gradient = np.dot(X.T, (h - y)) / y.size\n",
    "            self.theta -= self.lr * gradient\n",
    "            \n",
    "            if(self.verbose == True and i % 10000 == 0):\n",
    "                z = np.dot(X, self.theta)\n",
    "                h = self.__sigmoid(z)\n",
    "                print(f'loss: {self.__loss(h, y)} \\t')\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = self.__add_intercept(X)\n",
    "    \n",
    "        return self.__sigmoid(np.dot(X, self.theta))\n",
    "    \n",
    "    \n",
    "    def predict(self, X, threshold):\n",
    "        return self.predict_prob(X) >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 s, sys: 0 ns, total: 3 s\n",
      "Wall time: 3 s\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(lr=0.1, num_iter=300000)\n",
    "%time model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X, 0.5)\n",
    "# accuracy\n",
    "(preds == y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['feature_names'], ['target'], ['target_names'], ['DESCR'], ['data']]\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    " \n",
    "# Split a dataset into k folds\n",
    "\n",
    "def cross_validation_split(dataset, folds=3):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / folds)\n",
    "    for i in range(folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "            dataset_split.append(fold)\n",
    "    return dataset_split\n",
    " \n",
    "# test cross validation split\n",
    "#seed(1)\n",
    "#dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n",
    "folds = cross_validation_split(iris, 5)\n",
    "print(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=cross_validation_split(np.array([[1,2],[2,3],[4,5],[5,6]]), folds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([5, 6])], [array([1, 2])], [array([2, 3])]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['feature_names'], ['target'], ['target_names'], ['DESCR'], ['data']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv(k,x):\n",
    "    split=[]\n",
    "    m=len(x)\n",
    "    size=int(m/k)\n",
    "    for alpha in range(k):\n",
    "        x_new=x[alpha*size:(alpha+1)*size,:]\n",
    "        split.append(x_new)\n",
    "        x_new=0\n",
    "    if m%k==0:\n",
    "        return split\n",
    "    else:\n",
    "        split[0]=np.vstack((split[0],x[m-1,:]))\n",
    "        return split    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-54-522578b82363>(8)k_fold_cv()\n",
      "-> x_new=x[alpha*size:(alpha+1)*size,:]\n",
      "(Pdb) c\n",
      "> <ipython-input-54-522578b82363>(7)k_fold_cv()\n",
      "-> pdb=pdb.set_trace()\n",
      "(Pdb) c\n"
     ]
    }
   ],
   "source": [
    "t=k_fold_cv(2,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "        pdb=pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=t[0]==t[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [[5.1 3.5]\n",
      " [4.9 3. ]\n",
      " [4.7 3.2]\n",
      " [4.6 3.1]\n",
      " [4.6 3.4]\n",
      " [5.  3.4]\n",
      " [4.4 2.9]\n",
      " [4.9 3.1]\n",
      " [5.4 3.7]\n",
      " [4.8 3.4]\n",
      " [4.8 3. ]\n",
      " [4.3 3. ]\n",
      " [5.7 4.4]\n",
      " [5.4 3.4]\n",
      " [5.1 3.7]\n",
      " [4.6 3.6]\n",
      " [5.1 3.3]\n",
      " [4.8 3.4]\n",
      " [5.  3. ]\n",
      " [5.  3.4]\n",
      " [5.2 3.5]\n",
      " [4.8 3.1]\n",
      " [5.2 4.1]\n",
      " [4.9 3.1]\n",
      " [5.5 3.5]\n",
      " [4.9 3.6]\n",
      " [4.4 3. ]\n",
      " [5.1 3.4]\n",
      " [4.5 2.3]\n",
      " [5.  3.5]\n",
      " [5.1 3.8]\n",
      " [4.6 3.2]\n",
      " [5.  3.3]\n",
      " [7.  3.2]\n",
      " [6.9 3.1]\n",
      " [5.7 2.8]\n",
      " [4.9 2.4]\n",
      " [5.  2. ]\n",
      " [5.9 3. ]\n",
      " [6.  2.2]\n",
      " [6.1 2.9]\n",
      " [5.6 2.9]\n",
      " [6.7 3.1]\n",
      " [5.8 2.7]\n",
      " [6.2 2.2]\n",
      " [5.9 3.2]\n",
      " [6.1 2.8]\n",
      " [6.3 2.5]\n",
      " [6.4 2.9]\n",
      " [6.8 2.8]\n",
      " [5.7 2.6]\n",
      " [5.5 2.4]\n",
      " [5.5 2.4]\n",
      " [5.8 2.7]\n",
      " [6.  2.7]\n",
      " [6.  3.4]\n",
      " [6.7 3.1]\n",
      " [6.3 2.3]\n",
      " [5.6 3. ]\n",
      " [5.5 2.5]\n",
      " [5.  2.3]\n",
      " [5.7 3. ]\n",
      " [5.7 2.9]\n",
      " [6.2 2.9]\n",
      " [6.3 3.3]\n",
      " [5.8 2.7]\n",
      " [6.5 3. ]\n",
      " [7.6 3. ]\n",
      " [4.9 2.5]\n",
      " [7.3 2.9]\n",
      " [7.2 3.6]\n",
      " [6.5 3.2]\n",
      " [6.4 2.7]\n",
      " [5.7 2.5]\n",
      " [6.4 3.2]\n",
      " [6.5 3. ]\n",
      " [7.7 3.8]\n",
      " [5.6 2.8]\n",
      " [7.7 2.8]\n",
      " [6.3 2.7]\n",
      " [6.7 3.3]\n",
      " [6.2 2.8]\n",
      " [6.1 3. ]\n",
      " [7.2 3. ]\n",
      " [7.4 2.8]\n",
      " [6.4 2.8]\n",
      " [6.3 2.8]\n",
      " [6.1 2.6]\n",
      " [6.3 3.4]\n",
      " [6.4 3.1]\n",
      " [6.  3. ]\n",
      " [6.9 3.1]\n",
      " [6.7 3.1]\n",
      " [5.8 2.7]\n",
      " [6.8 3.2]\n",
      " [6.7 3.3]\n",
      " [6.7 3. ]\n",
      " [6.5 3. ]\n",
      " [6.2 3.4]\n",
      " [5.9 3. ]], test: [[5.  3.6]\n",
      " [5.4 3.9]\n",
      " [5.8 4. ]\n",
      " [5.4 3.9]\n",
      " [5.1 3.5]\n",
      " [5.7 3.8]\n",
      " [5.1 3.8]\n",
      " [5.2 3.4]\n",
      " [4.7 3.2]\n",
      " [5.4 3.4]\n",
      " [5.5 4.2]\n",
      " [5.  3.2]\n",
      " [5.  3.5]\n",
      " [4.4 3.2]\n",
      " [5.1 3.8]\n",
      " [4.8 3. ]\n",
      " [5.3 3.7]\n",
      " [6.4 3.2]\n",
      " [5.5 2.3]\n",
      " [6.5 2.8]\n",
      " [6.3 3.3]\n",
      " [6.6 2.9]\n",
      " [5.2 2.7]\n",
      " [5.6 3. ]\n",
      " [5.6 2.5]\n",
      " [6.1 2.8]\n",
      " [6.6 3. ]\n",
      " [6.7 3. ]\n",
      " [6.  2.9]\n",
      " [5.4 3. ]\n",
      " [5.5 2.6]\n",
      " [6.1 3. ]\n",
      " [5.8 2.6]\n",
      " [5.6 2.7]\n",
      " [5.1 2.5]\n",
      " [5.7 2.8]\n",
      " [7.1 3. ]\n",
      " [6.3 2.9]\n",
      " [6.7 2.5]\n",
      " [6.8 3. ]\n",
      " [5.8 2.8]\n",
      " [7.7 2.6]\n",
      " [6.  2.2]\n",
      " [6.9 3.2]\n",
      " [7.2 3.2]\n",
      " [6.4 2.8]\n",
      " [7.9 3.8]\n",
      " [7.7 3. ]\n",
      " [6.9 3.1]\n",
      " [6.3 2.5]]\n",
      "train: [[5.1 3.5]\n",
      " [4.9 3. ]\n",
      " [4.6 3.1]\n",
      " [5.  3.6]\n",
      " [5.4 3.9]\n",
      " [5.  3.4]\n",
      " [4.4 2.9]\n",
      " [4.3 3. ]\n",
      " [5.8 4. ]\n",
      " [5.7 4.4]\n",
      " [5.4 3.9]\n",
      " [5.1 3.5]\n",
      " [5.7 3.8]\n",
      " [5.1 3.8]\n",
      " [5.4 3.4]\n",
      " [5.1 3.7]\n",
      " [4.6 3.6]\n",
      " [4.8 3.4]\n",
      " [5.  3. ]\n",
      " [5.  3.4]\n",
      " [5.2 3.4]\n",
      " [4.7 3.2]\n",
      " [4.8 3.1]\n",
      " [5.4 3.4]\n",
      " [5.5 4.2]\n",
      " [5.  3.2]\n",
      " [4.9 3.6]\n",
      " [5.  3.5]\n",
      " [4.5 2.3]\n",
      " [4.4 3.2]\n",
      " [5.  3.5]\n",
      " [5.1 3.8]\n",
      " [4.8 3. ]\n",
      " [4.6 3.2]\n",
      " [5.3 3.7]\n",
      " [5.  3.3]\n",
      " [7.  3.2]\n",
      " [6.4 3.2]\n",
      " [6.9 3.1]\n",
      " [5.5 2.3]\n",
      " [6.5 2.8]\n",
      " [6.3 3.3]\n",
      " [4.9 2.4]\n",
      " [6.6 2.9]\n",
      " [5.2 2.7]\n",
      " [5.  2. ]\n",
      " [5.9 3. ]\n",
      " [6.1 2.9]\n",
      " [5.6 3. ]\n",
      " [6.2 2.2]\n",
      " [5.6 2.5]\n",
      " [5.9 3.2]\n",
      " [6.1 2.8]\n",
      " [6.3 2.5]\n",
      " [6.1 2.8]\n",
      " [6.6 3. ]\n",
      " [6.8 2.8]\n",
      " [6.7 3. ]\n",
      " [6.  2.9]\n",
      " [5.7 2.6]\n",
      " [5.5 2.4]\n",
      " [5.5 2.4]\n",
      " [5.8 2.7]\n",
      " [5.4 3. ]\n",
      " [6.7 3.1]\n",
      " [5.6 3. ]\n",
      " [5.5 2.6]\n",
      " [6.1 3. ]\n",
      " [5.8 2.6]\n",
      " [5.6 2.7]\n",
      " [5.7 2.9]\n",
      " [5.1 2.5]\n",
      " [5.7 2.8]\n",
      " [5.8 2.7]\n",
      " [7.1 3. ]\n",
      " [6.3 2.9]\n",
      " [4.9 2.5]\n",
      " [6.7 2.5]\n",
      " [6.8 3. ]\n",
      " [5.8 2.8]\n",
      " [6.4 3.2]\n",
      " [7.7 2.6]\n",
      " [6.  2.2]\n",
      " [6.9 3.2]\n",
      " [5.6 2.8]\n",
      " [7.2 3.2]\n",
      " [6.4 2.8]\n",
      " [7.2 3. ]\n",
      " [7.9 3.8]\n",
      " [6.3 2.8]\n",
      " [6.1 2.6]\n",
      " [7.7 3. ]\n",
      " [6.3 3.4]\n",
      " [6.4 3.1]\n",
      " [6.7 3.1]\n",
      " [6.9 3.1]\n",
      " [5.8 2.7]\n",
      " [6.8 3.2]\n",
      " [6.3 2.5]\n",
      " [6.5 3. ]], test: [[4.7 3.2]\n",
      " [4.6 3.4]\n",
      " [4.9 3.1]\n",
      " [5.4 3.7]\n",
      " [4.8 3.4]\n",
      " [4.8 3. ]\n",
      " [5.1 3.3]\n",
      " [5.2 3.5]\n",
      " [5.2 4.1]\n",
      " [4.9 3.1]\n",
      " [5.5 3.5]\n",
      " [4.4 3. ]\n",
      " [5.1 3.4]\n",
      " [5.1 3.8]\n",
      " [5.7 2.8]\n",
      " [6.  2.2]\n",
      " [5.6 2.9]\n",
      " [6.7 3.1]\n",
      " [5.8 2.7]\n",
      " [6.4 2.9]\n",
      " [6.  2.7]\n",
      " [6.  3.4]\n",
      " [6.3 2.3]\n",
      " [5.5 2.5]\n",
      " [5.  2.3]\n",
      " [5.7 3. ]\n",
      " [6.2 2.9]\n",
      " [6.3 3.3]\n",
      " [6.5 3. ]\n",
      " [7.6 3. ]\n",
      " [7.3 2.9]\n",
      " [7.2 3.6]\n",
      " [6.5 3.2]\n",
      " [6.4 2.7]\n",
      " [5.7 2.5]\n",
      " [6.5 3. ]\n",
      " [7.7 3.8]\n",
      " [7.7 2.8]\n",
      " [6.3 2.7]\n",
      " [6.7 3.3]\n",
      " [6.2 2.8]\n",
      " [6.1 3. ]\n",
      " [7.4 2.8]\n",
      " [6.4 2.8]\n",
      " [6.  3. ]\n",
      " [6.9 3.1]\n",
      " [6.7 3.3]\n",
      " [6.7 3. ]\n",
      " [6.2 3.4]\n",
      " [5.9 3. ]]\n",
      "train: [[4.7 3.2]\n",
      " [5.  3.6]\n",
      " [5.4 3.9]\n",
      " [4.6 3.4]\n",
      " [4.9 3.1]\n",
      " [5.4 3.7]\n",
      " [4.8 3.4]\n",
      " [4.8 3. ]\n",
      " [5.8 4. ]\n",
      " [5.4 3.9]\n",
      " [5.1 3.5]\n",
      " [5.7 3.8]\n",
      " [5.1 3.8]\n",
      " [5.1 3.3]\n",
      " [5.2 3.5]\n",
      " [5.2 3.4]\n",
      " [4.7 3.2]\n",
      " [5.4 3.4]\n",
      " [5.2 4.1]\n",
      " [5.5 4.2]\n",
      " [4.9 3.1]\n",
      " [5.  3.2]\n",
      " [5.5 3.5]\n",
      " [4.4 3. ]\n",
      " [5.1 3.4]\n",
      " [5.  3.5]\n",
      " [4.4 3.2]\n",
      " [5.1 3.8]\n",
      " [4.8 3. ]\n",
      " [5.1 3.8]\n",
      " [5.3 3.7]\n",
      " [6.4 3.2]\n",
      " [5.5 2.3]\n",
      " [6.5 2.8]\n",
      " [5.7 2.8]\n",
      " [6.3 3.3]\n",
      " [6.6 2.9]\n",
      " [5.2 2.7]\n",
      " [6.  2.2]\n",
      " [5.6 2.9]\n",
      " [6.7 3.1]\n",
      " [5.6 3. ]\n",
      " [5.8 2.7]\n",
      " [5.6 2.5]\n",
      " [6.1 2.8]\n",
      " [6.4 2.9]\n",
      " [6.6 3. ]\n",
      " [6.7 3. ]\n",
      " [6.  2.9]\n",
      " [6.  2.7]\n",
      " [5.4 3. ]\n",
      " [6.  3.4]\n",
      " [6.3 2.3]\n",
      " [5.5 2.5]\n",
      " [5.5 2.6]\n",
      " [6.1 3. ]\n",
      " [5.8 2.6]\n",
      " [5.  2.3]\n",
      " [5.6 2.7]\n",
      " [5.7 3. ]\n",
      " [6.2 2.9]\n",
      " [5.1 2.5]\n",
      " [5.7 2.8]\n",
      " [6.3 3.3]\n",
      " [7.1 3. ]\n",
      " [6.3 2.9]\n",
      " [6.5 3. ]\n",
      " [7.6 3. ]\n",
      " [7.3 2.9]\n",
      " [6.7 2.5]\n",
      " [7.2 3.6]\n",
      " [6.5 3.2]\n",
      " [6.4 2.7]\n",
      " [6.8 3. ]\n",
      " [5.7 2.5]\n",
      " [5.8 2.8]\n",
      " [6.5 3. ]\n",
      " [7.7 3.8]\n",
      " [7.7 2.6]\n",
      " [6.  2.2]\n",
      " [6.9 3.2]\n",
      " [7.7 2.8]\n",
      " [6.3 2.7]\n",
      " [6.7 3.3]\n",
      " [7.2 3.2]\n",
      " [6.2 2.8]\n",
      " [6.1 3. ]\n",
      " [6.4 2.8]\n",
      " [7.4 2.8]\n",
      " [7.9 3.8]\n",
      " [6.4 2.8]\n",
      " [7.7 3. ]\n",
      " [6.  3. ]\n",
      " [6.9 3.1]\n",
      " [6.9 3.1]\n",
      " [6.7 3.3]\n",
      " [6.7 3. ]\n",
      " [6.3 2.5]\n",
      " [6.2 3.4]\n",
      " [5.9 3. ]], test: [[5.1 3.5]\n",
      " [4.9 3. ]\n",
      " [4.6 3.1]\n",
      " [5.  3.4]\n",
      " [4.4 2.9]\n",
      " [4.3 3. ]\n",
      " [5.7 4.4]\n",
      " [5.4 3.4]\n",
      " [5.1 3.7]\n",
      " [4.6 3.6]\n",
      " [4.8 3.4]\n",
      " [5.  3. ]\n",
      " [5.  3.4]\n",
      " [4.8 3.1]\n",
      " [4.9 3.6]\n",
      " [4.5 2.3]\n",
      " [5.  3.5]\n",
      " [4.6 3.2]\n",
      " [5.  3.3]\n",
      " [7.  3.2]\n",
      " [6.9 3.1]\n",
      " [4.9 2.4]\n",
      " [5.  2. ]\n",
      " [5.9 3. ]\n",
      " [6.1 2.9]\n",
      " [6.2 2.2]\n",
      " [5.9 3.2]\n",
      " [6.1 2.8]\n",
      " [6.3 2.5]\n",
      " [6.8 2.8]\n",
      " [5.7 2.6]\n",
      " [5.5 2.4]\n",
      " [5.5 2.4]\n",
      " [5.8 2.7]\n",
      " [6.7 3.1]\n",
      " [5.6 3. ]\n",
      " [5.7 2.9]\n",
      " [5.8 2.7]\n",
      " [4.9 2.5]\n",
      " [6.4 3.2]\n",
      " [5.6 2.8]\n",
      " [7.2 3. ]\n",
      " [6.3 2.8]\n",
      " [6.1 2.6]\n",
      " [6.3 3.4]\n",
      " [6.4 3.1]\n",
      " [6.7 3.1]\n",
      " [5.8 2.7]\n",
      " [6.8 3.2]\n",
      " [6.5 3. ]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from sklearn.model_selection import KFold\n",
    "# data sample\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]\n",
    "y = (iris.target != 0) * 1\n",
    "# prepare cross validation\n",
    "kfold = KFold(3, True, 1)\n",
    "# enumerate splits\n",
    "for train, test in kfold.split(X):\n",
    "\tprint('train: %s, test: %s' % (X[train], X[test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [  0   1   2   3   6   7   8   9  10  11  12  13  15  20  21  22  23  24\n",
      "  25  26  27  30  32  34  36  37  38  39  41  43  46  47  49  50  52  55\n",
      "  57  60  61  62  63  64  65  67  68  70  71  72  74  76  79  80  81  82\n",
      "  83  85  86  87  88  89  93  95  96  97 100 101 104 105 106 107 109 110\n",
      " 111 113 115 116 117 121 122 123 124 126 127 129 130 132 133 134 136 137\n",
      " 138 139 140 142 143 144 145 147 148 149], test: [  4   5  14  16  17  18  19  28  29  31  33  35  40  42  44  45  48  51\n",
      "  53  54  56  58  59  66  69  73  75  77  78  84  90  91  92  94  98  99\n",
      " 102 103 108 112 114 118 119 120 125 128 131 135 141 146]\n",
      "train: [  0   1   3   4   5   7   8  13  14  15  16  17  18  19  20  21  22  24\n",
      "  25  26  28  29  30  31  33  35  37  40  41  42  43  44  45  47  48  49\n",
      "  50  51  52  53  54  56  57  58  59  60  61  63  66  68  69  70  71  72\n",
      "  73  75  76  77  78  79  80  81  82  84  86  88  90  91  92  94  96  98\n",
      "  99 101 102 103 106 108 112 114 115 118 119 120 121 125 128 129 131 133\n",
      " 134 135 136 137 140 141 142 143 146 147], test: [  2   6   9  10  11  12  23  27  32  34  36  38  39  46  55  62  64  65\n",
      "  67  74  83  85  87  89  93  95  97 100 104 105 107 109 110 111 113 116\n",
      " 117 122 123 124 126 127 130 132 138 139 144 145 148 149]\n",
      "train: [  2   4   5   6   9  10  11  12  14  16  17  18  19  23  27  28  29  31\n",
      "  32  33  34  35  36  38  39  40  42  44  45  46  48  51  53  54  55  56\n",
      "  58  59  62  64  65  66  67  69  73  74  75  77  78  83  84  85  87  89\n",
      "  90  91  92  93  94  95  97  98  99 100 102 103 104 105 107 108 109 110\n",
      " 111 112 113 114 116 117 118 119 120 122 123 124 125 126 127 128 130 131\n",
      " 132 135 138 139 141 144 145 146 148 149], test: [  0   1   3   7   8  13  15  20  21  22  24  25  26  30  37  41  43  47\n",
      "  49  50  52  57  60  61  63  68  70  71  72  76  79  80  81  82  86  88\n",
      "  96 101 106 115 121 129 133 134 136 137 140 142 143 147]\n"
     ]
    }
   ],
   "source": [
    "# enumerate splits\n",
    "for train, test in kfold.split(X):\n",
    "\tprint('train: %s, test: %s' % (train, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [150, 10]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-b5c88ad5cf8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mskf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train: %s test: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aims/.local/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0mset\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthat\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \"\"\"\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aims/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aims/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 205\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [150, 10]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    " \n",
    "n_splits = 3\n",
    " \n",
    "#X = np.ones(10)\n",
    "y = np.arange(1,11,dtype=float)\n",
    " \n",
    "# binning to make StratifiedKFold work\n",
    "yc = np.outer(y[::n_splits],np.ones(n_splits)).flatten()[:len(y)]\n",
    "yc[-n_splits:]=yc[-n_splits]*np.ones(n_splits)\n",
    " \n",
    "skf = StratifiedKFold(n_splits=n_splits)\n",
    "for train, test in skf.split(X, yc):\n",
    "    print(\"train: %s test: %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-78-820371e971a3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-78-820371e971a3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    1- Randomly split D into k subsets of size m/k\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "1- Randomly split D into k subsets of size m/k\n",
    "   for each model Mi\n",
    "    for each j= 1,...,k\n",
    "    Train Mi on  D-D_j\n",
    "    Test Mij on D_j -----> ld_j(Mij)\n",
    "    generalize error of Mi-----> Average of ld_j(Mij)\n",
    "    \n",
    "2- def k_fold_cv(k,x):\n",
    "    split=[]\n",
    "    m=len(x)\n",
    "    size=int(m/k)\n",
    "    for i in range(k):\n",
    "        x_new=x[i*size:(i+1)*size,:]\n",
    "        split.append(x_new)\n",
    "        x_new=0\n",
    "    if m%k=0:\n",
    "        return split\n",
    "    else:\n",
    "        split[0]=np.vstack((split[0],x[m-1,:]))\n",
    "        return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_elimination(data,target,significance_level=0.05):\n",
    "    feature=data.columns.tolist()\n",
    "    while(len(feature)>0):\n",
    "        feature_with_constant=sm.add_contant(data[feature])\n",
    "        p_value=sm.OLS(target,feature_with_constant).fit().p.value[1:]\n",
    "        max_p_value=p.value.max()\n",
    "        if max_p_value>=significance_level:\n",
    "            exited_feature=p_value.idXmax()\n",
    "            feature.remove(exited_feature)\n",
    "        else:\n",
    "            break\n",
    "            return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
